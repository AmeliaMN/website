\documentclass[10pt]{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr,url,hyperref}
\usepackage{graphicx,xspace}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,decorations.pathmorphing,backgrounds,positioning,fit,through}

\oddsidemargin 0in  %0.5in
\topmargin     0in
\leftmargin    0in
\rightmargin   0in
\textheight    9in
\textwidth     6in %6in
%\headheight    0in
%\headsep       0in
%\footskip      0.5in

\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem{conjecture}{Conjecture}

\pagestyle{fancy}

\lhead{\textsc{Prof. McNamara}}
\chead{\textsc{SDS/MTH 291: Lecture notes}}
\lfoot{}
\cfoot{}
%\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\ans}{\vspace{0.25in}}
\newcommand{\R}{{\sf R}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}}
\DeclareMathOperator{\Ex}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}

\rhead{\textsc{October 18, 2016}}

\begin{document}
\SweaveOpts{concordance=TRUE}

\paragraph{Agenda}
\begin{enumerate}
  \itemsep0em
  \item Multicollinearity and variance inflation factor
  \item More examples of multiple regression
  \item Regression summary lab?
\end{enumerate}

\paragraph{Multicollinearity}

Sometimes explanatory variables are highly correlated. This can cause oddities in regression output, since the effect of one variable may be confounded by another with which it is highly correlated.

Lets consider an example. The predictors \texttt{read} and \texttt{write} are both highly correlated with \texttt{math}. But, they are also correlated with each other.

<<echo=FALSE, message=FALSE, warning=FALSE,fig.height=6>>=
require(mosaic)
require(openintro)
require(gridExtra)
x1 <- xyplot(math~read, data=hsb2)
x2 <- xyplot(math~write, data=hsb2)
x3 <- xyplot(read~write, data=hsb2)
grid.arrange(x1,x2,x3, ncol=2)
@



<<size='footnotesize'>>=
m2 <- lm(math~read+write, data=hsb2)
summary(m2)
m3 <- lm(math~read+write+read*write, data=hsb2)
summary(m3)
@

\begin{enumerate}
  \itemsep0.5in
  \item What happens if we include their interaction term in a model?
\end{enumerate}

\paragraph{Variance inflation factor}
Geometrically, if two vectors are strongly correlated, then they point more or less in the same direction, and the plane through those vectors will be wobbly.

How do we know if we have multicollinearity? Define
 		$$
 			VIF_i = \frac{1}{1-R_i^2},
 		$$
 		where $R_i^2$ is the $R^2$ for a regression of $X_i \sim \sum_{j \neq i} X_j$. A common rule of thumb is that $VIF_i > 5 \rightarrow R_i^2 > 0.8$ implies multicollinearity.

Remedies:
 		\begin{enumerate}
 			\item Drop some predictors
 			\item Combine some predictors (e.g. survey questions)
 			\item Discount the coefficient $t$-tests
 		\end{enumerate}


<<message=FALSE, warning=FALSE, size='footnotesize'>>=
require(car)
Credit <- read.csv("Credit.csv")
m4 <- lm(Balance~Age+Rating+Limit, data=Credit)
summary(m4)
vif(m4)
Credit %>%
  select(Age, Rating, Limit, Balance) %>%
  cor()
# cor(Credit[,c("Age", "Rating", "Limit", "Balance")]) #this also works
@

\begin{enumerate}
  \itemsep0.5in
  \item Which variables are the most highly correlated?
  \item Which terms in the model have the highest VIF?
  \item Which term(s) would you drop from the model to try again?
  \vspace{0.5in}
\end{enumerate}

\paragraph{Scales of variables}
The scale of variables makes a difference to your model interpretation. 

<<message=FALSE, warning=FALSE, size='footnotesize'>>=
require(mosaic)
data(Salaries)
head(Salaries)
m1 <- lm(yrs.service~yrs.since.phd + salary, data=Salaries)
summary(m1)
@

\begin{enumerate}
  \itemsep0.5in
  \item Write out the regression equation, paying attention to the scale of the variables. 
  \item Interpret the coefficient on \verb#salary#
  \item Does this model make intuitive sense?
  \item Predict the number of years of service the model would expect for a professor 5 years out of their PhD making \$80,000. 
  \vspace{0.5in}
\end{enumerate}

<<size='footnotesize'>>=
Salaries = Salaries %>%
  mutate(salaryThou = salary/1000)
head(Salaries)
m2 <- lm(yrs.service~yrs.since.phd + salaryThou, data=Salaries)
summary(m2)
@

\begin{enumerate}
  \itemsep0.5in
  \item Write out the regression equation, paying attention to the scale of the variables. 
  \item Interpret the coefficient on \verb#salaryThou#
  \item Predict the number of years of service the model would expect for a professor 5 years out of their PhD making \$80,000. 
  \item How do the p-values and predictions compare to the unscaled version?
\end{enumerate}




\end{document}