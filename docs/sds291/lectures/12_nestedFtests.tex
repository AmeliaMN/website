\documentclass[10pt]{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr,url,hyperref}
\usepackage{graphicx,xspace}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,decorations.pathmorphing,backgrounds,positioning,fit,through}

\oddsidemargin 0in  %0.5in
\topmargin     0in
\leftmargin    0in
\rightmargin   0in
\textheight    9in
\textwidth     6in %6in
%\headheight    0in
%\headsep       0in
%\footskip      0.5in

\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem{conjecture}{Conjecture}

\pagestyle{fancy}

\lhead{\textsc{Prof. McNamara}}
\chead{\textsc{SDS/MTH 291: Lecture notes}}
\lfoot{}
\cfoot{}
%\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\ans}{\vspace{0.25in}}
\newcommand{\R}{{\sf R}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}}
\DeclareMathOperator{\Ex}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}

\rhead{\textsc{October 27, 2016}}

\usepackage{Sweave}
\begin{document}
\input{12_nestedFtests-concordance}

\paragraph{Agenda}
\begin{enumerate}
  \itemsep0em
  \item Announcements
  \item Review about partitioning variability
  \item Nested F-tests
  \item Regression summary lab
\end{enumerate}

\paragraph{Announcements}
\begin{itemize}
\item Remember that initial project proposal are due Friday at midnight
\item Homework 7 due Monday
\item Reading quiz on chapter 3 due next Wednesday
\end{itemize}

\paragraph{Review of partitioning variability}
When we do Analysis of Variance (ANOVA) we are partitioning the variability. Recall:

\begin{eqnarray*}
\sum_{i=1}^n (y_i -\bar{y})^2 &=& \sum_{i=1}^n (\hat{y_i}-\bar{y}) + \sum_{i=1}^n (y_i-\hat{y_i})^2 \\
SST &=& SSM + SSE
\end{eqnarray*}

We have also defined
\begin{eqnarray*}
SXX &=& \sum_{i=1}^n (x_i - \bar{x})^2 \\
SXY &=& \sum_{i=1}^n (x_i - \bar{x})\cdot(y_i - \bar{y})
\end{eqnarray*}

And
\begin{eqnarray*}
\hat{\beta_1} = \frac{SXY}{SXX}
\end{eqnarray*}

Then, because we know the point $(\bar{y}, \bar{x})$ lies on the line, we can solve for $\hat{\beta_0}$,

\begin{eqnarray*}
\hat{\beta_0} = \bar{y}-\hat{\beta_1}\cdot\bar{x} 
\end{eqnarray*}




\paragraph{Nested $F$-tests}

Individual t-tests in the regression summary have given us a way to test the statistical significant of individual terms in our model. But what if we want to test the significance of the contribution to the model by a \emph{subset} of the predictors? That is where the nested F-test comes in. 
  \begin{itemize}
		\item $H_0$: $\beta_i=0$ for all predictors in the subset
		\item $H_{A}$: at least one $\beta_i \neq 0$
		$$
			F = \frac{(SSM_{full} - SSM_{reduced}) / (\text{\# of predictors tested})}{SSE_{full} / (n-k-1)} ,
		$$
		where $k$ is the \# of predictors in the full model
		\item Use \texttt{anova} command in R, being careful that terms in the model are \emph{nested}.
	\end{itemize}
\clearpage
\paragraph{Regression summary lab}
Some code for your reference
\begin{Schunk}
\begin{Sinput}
> require(mosaic)
> require(fueleconomy)
> data(vehicles)
> myCars <- vehicles %>%
+   filter(year == 2000 & cyl == 4)
> xyplot(hwy ~ displ, data=myCars, main="Fuel Economy", alpha=0.5, cex=2, pch=19, 
+        xlab="Engine Size (cubic centimeters)", ylab="Fuel Economy (miles per gallon)")
> m1 <- lm(hwy ~ displ, data=myCars)
> summary(m1)
> regdata <- myCars %>% 
+   mutate(xdif = displ - mean(displ),  ydif = hwy - mean(hwy))
> regdata <- regdata %>% 
+   summarize(SXX = sum(xdif^2),  SXY = sum(xdif*ydif))
> regdata <- regdata %>% 
+   mutate(beta1=SXY/SXX)
> regdata
> coef(m1)["displ"]
> myCars %>% 
+   mutate(xdif = displ - mean(displ),  ydif = hwy - mean(hwy)) %>% 
+   summarize(SXX = sum(xdif^2), SXY = sum(xdif*ydif), beta1=SXY/SXX) 
> myCars %>% 
+   summarize(n=n(), SXX = var(displ) * (n-1), SXY = cov(hwy,displ) * (n-1), beta1 = SXY/SXX)
> myCars %>% 
+   summarize(beta1 = cor(hwy, displ) * (sd(hwy) / sd(displ)))
> regdata <- myCars %>% 
+   summarize(beta1 = cor(hwy, displ) * (sd(hwy) / sd(displ)), meanX = mean(displ), meanY = mean(hwy))
> regdata %>% 
+   mutate(beta0 = meanY - beta1 * meanX)
> predict(m1, newdata=data.frame(displ=mean(~displ, data=myCars)))
> mean(~hwy, data=myCars)
> assessdata <- myCars %>% 
+   mutate(ydif = (hwy - mean(hwy)))
> assessdata <- assessdata %>% 
+   mutate(fitted = fitted(m1))
> assessdata <- assessdata %>%
+   summarize(n = n(), SST = sum(ydif^2), SSE = sum((fitted - hwy)^2), SSM = sum((fitted - mean(hwy))^2))
> assessdata %>% 
+   mutate(SSE + SSM)
> myCars %>% 
+   mutate(ydif = (hwy - mean(hwy)), fitted = fitted(m1))  %>%
+   summarize(SST = sum(ydif^2), SSE = sum((fitted - hwy)^2), SSM = sum((fitted - mean(hwy))^2))
> # Coefficient of determination
> assessdata <- assessdata %>% 
+   mutate(rsq = 1 - SSE / SST)
> rsquared(m1)
> # p is the number of explanatory variables
> p <- 1
> assessdata <- assessdata %>%
+   mutate(adjrsq = 1 - (SSE / (n-1-p)) / (SST / (n-1)))
> testdata <- myCars %>% 
+    mutate(ydif = (hwy - mean(hwy)), fitted = fitted(m1)) %>%
+   summarize(n=n(), meanX = mean(displ), meanY = mean(hwy),
+             SXX = var(displ) * (n-1), SXY = cov(hwy,displ) * (n-1),
+             beta1 = SXY/SXX, beta0 = meanY - beta1 * meanX,
+             SST = sum(ydif^2), SSE = sum((fitted - hwy)^2), SSM = sum((fitted - mean(hwy))^2))
> # Residual Standard error
> testdata <- testdata %>% 
+   mutate(RSE = sqrt(SSE / (n-2)))
> # Standard error 
> testdata <- testdata %>%
+   mutate(SE1 = RSE / sqrt(SXX))
> testdata %>% glimpse()
> # t-statistic
> testdata <- testdata %>%
+   mutate(t1 = beta1 / SE1)
> testdata %>% glimpse()
> # p-value
> testdata %>%
+   summarize(p = 2 * pt(abs(t1), df=(n-2), lower.tail = FALSE))
> # Compute statistics for the intercept
> # Standard error 
> testdata <- testdata %>%
+   mutate(SE0 = RSE * sqrt((1/n) + (meanX)^2 / SXX))
> # t-statistic
> testdata <- testdata %>%
+   mutate(t0 = beta0 / SE0)
> testdata %>% glimpse()
> # p-value
> testdata %>%
+   summarise(p = 2 * pt(abs(t0), df=(n-2), lower.tail = FALSE))
> anova(m1)
> # F-statistic
> testdata <- testdata %>%
+   mutate(F = (SSM / p) / (SSE / (n-1 - p)))
> testdata %>%
+   summarize(p = pf(F, df1 = p, df2 = n-1 - p, lower.tail=FALSE))
> bloodp <- read.csv("http://www.math.smith.edu/~bbaumer/mth247/labs/bloodpress.csv")
> library(GGally)
> ggpairs(bloodp)
> # pairs(bloodp) # this is a little faster, but uglier 
> 
> mfull <- lm(BP ~ ., data=bloodp)
> summary(mfull)
> require(car)
> vif(mfull)
> m1 <- lm(BP ~ Weight, data=bloodp)
> m2 <- lm(BP ~ Weight +  Age, data=bloodp)
> m3 <- lm(BP ~ Weight +  Age + Dur + Stress, data=bloodp)
> # Add the models in ascending order of complexity.
> anova(m1, m2, m3, mfull)
> anova(m2, mfull)
> SSM_full = sum((fitted.values(mfull) - mean(~BP, data=bloodp))^2)
> SSM_reduce = sum((fitted.values(m2) - mean(~BP, data=bloodp))^2)
> SSM_full - SSM_reduce
> SSE_full = sum(residuals(mfull)^2)
> SSE_full
> ((SSM_full - SSM_reduce)/4)/(SSE_full/(20-6-1))
\end{Sinput}
\end{Schunk}

\end{document}
