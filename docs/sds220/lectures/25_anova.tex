\documentclass[10pt]{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr,url,hyperref}
\usepackage{graphicx,xspace}
\usepackage{subfigure}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,positioning,fit,through}

\oddsidemargin 0in  %0.5in
\topmargin     0in
\leftmargin    0in
\rightmargin   0in
\textheight    9in
\textwidth     6in %6in
%\headheight    0in
%\headsep       0in
%\footskip      0.5in

\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem{conjecture}{Conjecture}

\pagestyle{fancy}

\lhead{\textsc{Prof. McNamara}}
\chead{\textsc{SDS/MTH 220: Lecture notes}}
\lfoot{}
\cfoot{}
%\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\ans}{\vspace{0.25in}}
\newcommand{\R}{{\sf R}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}}
\newcommand{\Ex}{\mathbb{E}}

\rhead{\textsc{November 17, 2017}}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\paragraph{Agenda}
\begin{enumerate}
  \itemsep0em
  \item Multiple Testing
  \item ANOVA

\end{enumerate}

\paragraph{Multiple Testing}

Why is this comic funny?: \url{http://xkcd.com/882/}

The simplest (and most conservative) way to correct for multiple testing is to use Bonferroni's correction: simply divide the $\alpha$-level by the number of comparisons that you are making. 


\paragraph{ANOVA} 
We just developed a way to compare differences in means between \emph{two} groups. But what if we have more than two groups? Analysis of Variance (ANOVA) provides a mechanism for simultaneously assessing the differences between multiple groups. 

\paragraph{Different notational formulations}
\begin{itemize}
  \item Consider the following formulations \emph{of the same model}:
  \begin{align*}
    y_{ij} &= \mu_i + \epsilon_{ij}, \text{ where } \epsilon_{ij} \sim N(0, \sigma) \\
    y_{ij} &= \mu + \alpha_i + \epsilon_{ij}, \text{ where } \epsilon_{ij} \sim N(0, \sigma) \\
    y_{ij} &= \mu_1 + \beta_i \cdot X_i + \epsilon_{ij}, \text{ where } \epsilon_{ij} \sim N(0, \sigma)
  \end{align*}
  for groups $i = 1,\ldots, I$ and individuals $j=1,\ldots,n_i$, with common standard deviation $\sigma$
  \item The $\mu_i$'s are the group means, $\mu$ is the grand mean, the $\alpha_i$'s are the group effects, and the $\beta_i$'s are the group effects relative to the \emph{reference group}.
  \item The models are the same, because the $\hat{y}_{ij}$'s are all the same.
  \end{itemize}


\paragraph{HELP study}

The HELP study was a clinical trial for adult inpatients recruited from a detoxification unit. Patients with no primary care physician were randomized to receive a multidisciplinary assessment and a brief motivational intervention or usual care, with the goal of linking them to primary medical care. We'll consider two variables:

\begin{itemize}
  \itemsep0in
  \item \cmd{cesd}: Center for Epidemiologic Studies Depression measure at baseline (high scores indicate more depressive symptoms)
  \item \cmd{substance}: primary substance of abuse: alcohol, cocaine, or heroin
\end{itemize}

Are there important differences in the depression scores among patients depending on their drug of abuse? 
\clearpage
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{require}\hlstd{(mosaic)}
\hlkwd{favstats}\hlstd{(cesd} \hlopt{~} \hlstd{substance,} \hlkwc{data} \hlstd{= HELPrct)}
\end{alltt}
\begin{verbatim}
##   substance min Q1 median Q3 max     mean       sd   n missing
## 1   alcohol   4 26     36 42  58 34.37288 12.05041 177       0
## 2   cocaine   1 19     30 39  60 29.42105 13.39740 152       0
## 3    heroin   4 28     35 43  56 34.87097 11.19812 124       0
\end{verbatim}
\begin{alltt}
\hlkwd{qplot}\hlstd{(}\hlkwc{y} \hlstd{= cesd,} \hlkwc{x} \hlstd{= substance,} \hlkwc{data} \hlstd{= HELPrct,} \hlkwc{geom} \hlstd{=} \hlstr{"boxplot"}\hlstd{)}
\hlkwd{anova}\hlstd{(}\hlkwd{aov}\hlstd{(cesd} \hlopt{~} \hlstd{substance,} \hlkwc{data} \hlstd{= HELPrct))}
\end{alltt}
\begin{verbatim}
## Analysis of Variance Table
## 
## Response: cesd
##            Df Sum Sq Mean Sq F value    Pr(>F)    
## substance   2   2704  1352.1  8.9363 0.0001563 ***
## Residuals 450  68084   151.3                      
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}
\end{kframe}
\end{knitrout}

\begin{enumerate}
  \itemsep1.25in
  \item Write down the null and alternative hypotheses
  \item Check the conditions for ANOVA: is independence reasonable? Is normality reasonable? What about equal variance?
  \item Find the value of the test statistic ($F$) in the ANOVA table. Can you derive it from the other numbers in the table?
  \item Draw a picture of the sampling distribution of $F$. How many degrees of freedom do we have?
  \item Find the p-value. [You will need the function \cmd{pf()}.]
  \item What do you conclude? Write a sentence summarizing your findings.
  \vspace{1.25in}
\end{enumerate}




{\bf In-Class Problem: 4.37 Chicken diet and weight}




% 
% \newpage
% 
% \paragraph{One-way ANOVA}
% 
% \begin{itemize}
%   \item Key insight: One-way ANOVA is just regression with a quantitative response variable and a single categorical explanatory variable
%   \item A two-sample t-test is just a special case of ANOVA where there are only two groups
%   \item Consider the following formulations \emph{of the same model}:
%   \begin{align*}
%     y_{ij} &= \mu_i + \epsilon_{ij}, \text{ where } \epsilon_{ij} \sim N(0, \sigma) \\
%     y_{ij} &= \mu + \alpha_i + \epsilon_{ij}, \text{ where } \epsilon_{ij} \sim N(0, \sigma) \\
%     y_{ij} &= \mu_1 + \beta_i \cdot X_i + \epsilon_{ij}, \text{ where } \epsilon_{ij} \sim N(0, \sigma)
%   \end{align*}
%   for groups $i = 1,\ldots, I$ and individuals $j=1,\ldots,n_i$, with common standard deviation $\sigma$
%   \item The $\mu_i$'s are the group means, $\mu$ is the grand mean, the $\alpha_i$'s are the group effects, and the $\beta_i$'s are the group effects relative to the \emph{reference group}.
%   \item The models are the same, because the $\hat{y}_{ij}$'s are all the same.
%   \item Let $X$ be the categorical variable that has a unique value for each of the $i = 1,\ldots,I$ groups. Furthermore, let $X_i$ be the indicator (binary) variable corresponding to the $i^{th}$ group.
%   \item The third model is exactly what happens when you compute {\tt lm(y $\sim$ x)} in R, with {\tt x} being a categorical variable
%   \item The pooled standard deviation $s_p$, a weighted average of the standard deviations of the groups, is an estimate of $\sigma$, the unknown common standard deviation. This equal to the residual standard error.
%   \item The null hypothesis for one-way ANOVA is that $\beta_i = 0$ for all $i=1,\ldots,I-1$
%   \item The sum of squares and degrees of freedom are partitioned similarly as
%   $$
%     SS_{Total} = SS_{Groups} + SS_{Residuals} \, , \qquad d.f._{Total} = d.f._{Groups} + d.f._{Residuals}
%   $$
% \end{itemize}
% 
% <<fig.show='hide'>>=
% grand_mean <- mean(~cesd, data = HELPrct)
% anova_plot <- qplot(y = cesd, x = substance, color = substance, data = HELPrct, alpha = 0.3) + 
%   geom_hline(yintercept = grand_mean)
% anova_plot
% 
% library(broom)
% mod_null <- lm(cesd ~ 1, data = HELPrct)
% mod_null %>%
%   augment() %>%
%   summarize(N = n(), SST = sum((cesd - .fitted)^2))
% @
% 
% <<fig.show='hide'>>=
% group_means <- HELPrct %>%
%   group_by(substance) %>%
%   summarize(N = n(), mean_cesd = mean(cesd))
% 
% anova_plot + geom_hline(data = group_means, size = 1.5, 
%                         aes(yintercept = mean_cesd, color = substance))
% 
% mod_substance <- lm(cesd ~ substance, data = HELPrct)
% mod_substance %>%
%   augment() %>%
%   summarize(N = n(), SST = sum((cesd - grand_mean)^2), 
%             SSE = sum((cesd - .fitted)^2), df1 = length(unique(.fitted)) - 1)
% @
% 
% \paragraph{Equivalence of two-sample t-test, ANOVA, and regression}
% 
% Note that the p-values are all exactly the same.
% 
% <<message=FALSE>>=
% require(openintro)
% gifted <- mutate(gifted, msmarter = motheriq > fatheriq)
% t.test(score ~ msmarter, data = gifted, var.equal = TRUE)
% anova(aov(score ~ msmarter, data = gifted))
% summary(lm(score ~ msmarter, data = gifted))
% @
% 
% However, the two-sample t-test with \emph{unequal} variance is slightly different:
% 
% <<>>=
% t.test(score ~ msmarter, data = gifted)
% @
% 
% 
% \paragraph{Solution to ANOVA}
% 
% We'll suppress the figure in the notes.
% 
% <<fig.height=4, fig.width=10, fig.show='hide'>>=
% plotDist("f", params = list(df1 = 2, df2 = 450))
% qf(0.95, df1 = 2, df2 = 450)
% pf(8.94, df1 = 2, df2 = 450, lower.tail = FALSE)
% @
% 
% \paragraph{Solution to Chicken diet}
% 
% <<fig.show='hide'>>=
% favstats(weight ~ feed, data = chickwts)
% qplot(y = weight, x = feed, data = chickwts, geom = "boxplot")
% anova(aov(weight ~ feed, data = chickwts))
% plotDist("f", params = list(df1 = 5, df2 = 65))
% qf(0.95, df1 = 5, df2 = 65)
% pf(15.36, df1 = 5, df2 = 65, lower.tail = FALSE)
% @
% 
% 
% \paragraph{Multiple Testing}
% 
% Two of the comparisons still pass after a Bonferroni correction.
% 
% <<size='footnotesize'>>=
% t.test(cesd ~ substance, data = filter(HELPrct, substance != "alcohol"))
% t.test(cesd ~ substance, data = filter(HELPrct, substance != "cocaine"))
% t.test(cesd ~ substance, data = filter(HELPrct, substance != "heroin"))
% @


\end{document}
