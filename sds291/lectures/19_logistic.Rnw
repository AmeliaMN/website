\documentclass[10pt]{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr,url,hyperref}
\usepackage{graphicx,xspace}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,decorations.pathmorphing,backgrounds,positioning,fit,through}

\oddsidemargin 0in  %0.5in
\topmargin     0in
\leftmargin    0in
\rightmargin   0in
\textheight    9in
\textwidth     6in %6in
%\headheight    0in
%\headsep       0in
%\footskip      0.5in

\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem{conjecture}{Conjecture}

\pagestyle{fancy}

\lhead{\textsc{Prof. McNamara}}
\chead{\textsc{SDS/MTH 291: Lecture notes}}
\lfoot{}
\cfoot{}
%\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\ans}{\vspace{0.25in}}
\newcommand{\R}{{\sf R}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}}
\DeclareMathOperator{\Ex}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\DeclareMathOperator{\X}{\mathbf{X}}
\DeclareMathOperator{\Hatmat}{\mathbf{H}}

\rhead{\textsc{November 29, 2016}}

\begin{document}

\paragraph{Agenda}
\begin{enumerate}
  \itemsep0em
  \item Logistic Regression
  \item Assessing Fit in Logistic Regression
\end{enumerate}

<<echo=FALSE>>=
opts_chunk$set(size='footnotesize')
@

\paragraph{Binary response}
	\begin{itemize}
		\item What do to when response variable $p$ is \emph{binary}?
		\item Linear model will produce illogical estimates (eg. $\hat{p} > 1$ or $ \hat{p} < 0$)
		\end{itemize}
		
<<message=FALSE, warning=FALSE, fig.height=3>>=
require(mosaic)
require(Stat2Data)
data(Whickham)
Whickham = Whickham %>%
  mutate(isAlive = 2 - as.numeric(outcome))
xyplot(isAlive~jitter(age), data=Whickham, pch=19, cex=1.5, alpha=0.05, col="black")
@

<<fig.height=3>>=
plotModel(lm(isAlive~age, data=Whickham), pch=19)
@

This doesn't make sense outside the $[0,1]$ range. One solution might be to summarize the data to be frequencies at each age. 
<<fig.height=3>>=
alive = Whickham %>%
  group_by(age, isAlive) %>% 
  summarize(total = n()) %>%
  mutate(freq = total / sum(total)) %>%
  filter(isAlive==1)
xyplot(freq~age, data=alive,pch=19, col="black")
@

<<fig.height=3>>=
xyplot(freq~age, data=alive, pch=19, type=c("p", "r"))
@

But, this still has strange interpretations. 

\paragraph{Logistic Regression}
What's the solution? Logistic regression! This uses the logit function as a `link.'
	\begin{itemize}
		\item logit produces S-curve that is always in $[0,1]$
		\item Fit via \emph{maximum likelihood estimation}, not OLS
		\item No such thing as $R^2$ or sum of squares
	\end{itemize}

\clearpage
	\paragraph{Warmup-- probability and odds}
Probabilities and odds express the same information, but have different interpretation. Lets fill in this chart to help warm up our intuition about their relationship.
\begin{center}
\begin{tabular}{|c|c|}
\hline
Probability of success ($\pi$) & Odds ($\pi/(1-\pi)$) \\
\hline
1/2 & 1/1 \\
& \\
\hline
1/3 & 1/2 \\
& \\
\hline
1/4 & \\
& \\
\hline 
1/5 & \\
& \\
\hline 
2/3 & \\
& \\
\hline 
3/4 & \\
& \\
\hline
\end{tabular}
\end{center}

\paragraph{``Spaces''}

We often talk about three `spaces' for logistic regression. These are just different ways of writing the same thing, but they have different interpretations so they are useful for different tasks. 

\begin{itemize}
\item Log odds space
	\begin{eqnarray*}
			\log \left( \frac{\pi}{1-\pi} \right) &=& \beta_0 + \beta_1\cdot X \\
		\end{eqnarray*}
		
		Thinking about log odds is useful when you want a linear form of a regression line. You can interpret the coefficients in the standard way we have been doing for linear regression, ``A one unit increase in $x$ is associated with a $\beta_1$ increase in the log odds of $y$''
		
<<fig.height=3>>=
m1 = glm(isAlive~age, data=Whickham, family=binomial)
xyplot(log(fitted.values(m1)/(1-fitted.values(m1)))~age, data=Whickham, type=c("l"),ylab="log odds")
@
\clearpage
		\item Odds space
		
		\begin{eqnarray*}
	    \frac{\pi}{1-\pi} &=& e^{\beta_0 + \beta_1\cdot X}
		\end{eqnarray*}

Odds are useful when you want to interpret the slope coefficient. We can use the interpretation, ``A one unit increase in $x$ is associated with changing $y$ by a factor of $e^{\beta_1}$. 

<<fig.height=3>>=
xyplot(fitted.values(m1)/(1-fitted.values(m1))~age, data=Whickham,  type="spline", ylab="odds")
@

\item Probability space
	\begin{eqnarray*}
			\pi &=& \frac{e^{\beta_0 + \beta_1\cdot X}}{1 + e^{\beta_0 + \beta_1\cdot X}}
		\end{eqnarray*}
		The probability form is how the model gets fit, but it does not have an easy interpretation for what happens with a change in $x$. 
<<fig.height=3>>=
plotModel(m1, ylab="probability")
@

\end{itemize}



	
% 	pg. 455, ``linear on the right, log(odds) on the left``
% 	Should do the math to go from log(odds) to probability and vice versa
% 	Do the math to show that the 50\% point is at $x=-\beta_0/\beta_1$
% 	Point out which pieces of this correspond to the CFAU framework. E.g., inference. 
%   pg. 525, comparison of tests and intervals for ordinary regression and logistic regression

\end{document}