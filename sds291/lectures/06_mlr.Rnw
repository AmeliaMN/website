\documentclass[10pt]{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr,url,hyperref}
\usepackage{graphicx,xspace}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,decorations.pathmorphing,backgrounds,positioning,fit,through}

\oddsidemargin 0in  %0.5in
\topmargin     0in
\leftmargin    0in
\rightmargin   0in
\textheight    9in
\textwidth     6in %6in
%\headheight    0in
%\headsep       0in
%\footskip      0.5in

\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem{conjecture}{Conjecture}

\pagestyle{fancy}

\lhead{\textsc{Prof. McNamara}}
\chead{\textsc{SDS/MTH 291: Lecture notes}}
\lfoot{}
\cfoot{}
%\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\ans}{\vspace{0.25in}}
\newcommand{\R}{{\sf R}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}}
\DeclareMathOperator{\Ex}{\mathbb{E}}
\DeclareMathOperator{\Var}{\text{Var}}

\rhead{\textsc{October 4th, 2016}}

\begin{document}

\paragraph{Agenda}
\begin{enumerate}
  \itemsep0em
  \item Multiple Linear Regression
    \begin{itemize}
    \item Formula/notation
    \item Parallel slopes
    \item Parallel planes
    \end{itemize}
\end{enumerate}



\paragraph{Multiple Regression}

Multiple regression is a natural extension of simple linear regression. 
\begin{itemize}
  \itemsep0in
  \item SLR: one response variable, one explanatory variable
  $$
    Y = \beta_0 + \beta_1 \cdot X + \epsilon, \text{ where } \epsilon \sim N(0, \sigma_\epsilon)
  $$
  \item MLR: one response variable, \emph{more than one} explanatory variable 
  $$
    Y = \beta_0 + \beta_1 \cdot X_1 + \beta_2 \cdot X_2 + \cdots + \beta_p \cdot X_p + \epsilon, \text{ where } \epsilon \sim N(0, \sigma_\epsilon)
  $$
  \item Estimated coefficients (e.g. $\hat{\beta}_i$'s) now are interpreted in relation to (or ``conditional on'') the other variables
  \item $\beta_i$ reflects the \emph{predicted} change in $Y$ associated with a one unit increase in $X_i$, conditional upon the rest of the $X_i$'s. 
  \item $R^2$ has the same interpretation (proportion of variability explained by the model)
\end{itemize}

\paragraph{Regression with a Categorical Variable}

Consider first the case where $X_1$ is an \emph{indicator} variable that can only be 0 or 1 (e.g. $isFemale$). Then,
$$
  \hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 \cdot X_1
$$
So then,
  \begin{align*}
    \text{For men, } \qquad \hat{Y} |_{ X_1 = 0} &= \hat{\beta}_0 \qquad \qquad \text{ [what value does }\hat{\beta}_0 \text{ take on?]} \\
    \text{For women, } \qquad \hat{Y} |_{ X_1 = 1} &= \hat{\beta}_0 + \hat{\beta}_1
  \end{align*}
\paragraph{Multiple Regression with a Categorical Variable}
More generally, consider the case where $X_1$ is quantitative, but $X_2$ is an indicator variable. Then,
  \begin{align*}
    \hat{Y} |_{ X_1, X_2 = 0} &= \hat{\beta}_0 + \hat{\beta}_1 \cdot X_1 \\ 
    \hat{Y} |_{ X_1, X_2 = 1} &= \hat{\beta}_0 + \hat{\beta}_1 \cdot X_1 + \hat{\beta}_2 \cdot 1 \\
      &= \left( \hat{\beta}_0 + \hat{\beta}_2 \right) + \hat{\beta}_1 \cdot X_1  
  \end{align*}
  This is called a \emph{parallel slopes} model. [Why?]
  
\paragraph{Example: Italian Restaurants}

The Zagat guide contains restaurant ratings and reviews for many major world cities. We want to understand variation in the average $Price$ of a dinner in Italian restaurants in New York City. Specifically, we want to know how customer ratings (measured on a scale of 0 to 30) of the $Food$, $Decor$, and $Service$, as well as whether the restaurant is located to the $East$ or west of 5th Avenue, are associated with the average $Price$ of a meal. The data contains ratings and prices for 168 Italian restaurants in 2001.

<<message=FALSE,warning=FALSE,fig.show='hold', fig.height=3>>=
require(mosaic)
NYC <- read.csv("http://www.stat.tamu.edu/~sheather/book/docs/datasets/nyc.csv")
xyplot(Price ~ jitter(Service), alpha=0.5,
  xlab="Jittered service rating", ylab="Average Price (US$)", pch=19, 
  cex=1.5, data=NYC)
m1 <- lm(Price ~ Service, data=NYC)
coef(m1)
@

\paragraph{In-Class Activity}

\begin{enumerate}
   \itemsep1.2in
  % \item Use {\tt xyplot()} to examine the bivariate relationships between $Price$, $Food$ and $Service$. 
  % \item What do you observe? Describe the form, direction, and strength of the relationships.
  \item Use {\tt lm()} to build a SLR model for $Price$ as a function of $Food$. Interpret the coefficients of this model. How is the quality of the food at these restaurants associated with its price? 
  \item Build a parallel slopes model by conditioning on the $East$ variable. Interpret the coefficients of this model. What is the value of being on the East Side of Fifth Avenue?
  \item Calculate the expected $Price$ of a restaurant in the East Village with a $Food$ rating of 23. 
  \item Add both regression lines to your scatterplot! [You can use plotModel to do this]
  
<<eval=FALSE>>=
m2 <- lm(Price ~ Food + East, data=NYC)
plotModel(m2)
@
  
\end{enumerate}


\paragraph{Multiple Regression with a Second Quantitative Variable}
If $X_2$ is a quantitative variable, then we have

  $$
    \hat{Y} = \hat{\beta}_0 + \hat{\beta}_1 \cdot X_1 + \hat{\beta}_2 \cdot X_2
  $$
Notice that our model is no longer a line, rather it is a \emph{plane} that lives in three dimensions!

\paragraph{Example: Italian Restaurants (continued)}

Now suppose that we want to improve our model by considering not only the quality of the $Food$, but also the quality of the $Service$. We can do this in {\tt R} by simply adding another variable to our regression model.

<<message=FALSE,fig.height=3, eval=TRUE>>=
m3 <- lm(Price ~ Food + Service, data=NYC)
coef(m3)
@

<<tidy=TRUE, eval=FALSE, echo=FALSE>>=
fit.price = makeFun(m3)
plotFun(fit.price(f,s) ~ f & s, surface=TRUE, f.lim=c(0,30), s.lim=c(0,30), alpha=0.5)
@

<<tidy=TRUE, eval=FALSE, echo=FALSE>>=
require(rgl)
opacity <- 0.4
with(NYC, plot3d(x = Food, y = Service, z = Price, type = "s", size = 0.3,
    col = "blue", xlab = "Food Rating", ylab = "Service Rating",
    zlab = "Price ($)"))
coefs <- coef(m3)
planes3d(coefs["Food"], coefs["Service"], -1, coefs["(Intercept)"], alpha = opacity,
col = "lightgray")
@

\begin{enumerate}
  \itemsep0.7in
  \item Interpret the coefficients of this model. What does the coefficient of $Food$ mean in the real-world context of the problem? $Service$?
  \item How important is $Service$ relative to $Food$? Is it fair to compare the two coefficients?
  \item Find the expected $Price$ of a restaurant with a $Food$ rating of 21 but a $Service$ rating of 28. [Use \texttt{predict()} or calculate by hand]
  \item Calculate the residual for \href{http://www.zagat.com/r/san-pietro-new-york}{San Pietro}. Is it overpriced? 
  <<>>=
NYC %>% filter(Restaurant == "San Pietro")
@


  \item What if we added all three explanatory variables to the model? What geometric shape would we have then? 


<<tidy=TRUE, eval=FALSE, echo=FALSE>>=
with(NYC, plot3d(x = Food, y = Service, z = Price, type = "s", size = 0.8,
    col = "blue", xlab = "Food Rating", ylab = "Service Rating",
    zlab = "Price ($)"))
coefs <- coef(lm(Price ~ Food + Service + East, data=NYC))
planes3d(coefs["Food"], coefs["Service"], -1, coefs["(Intercept)"], alpha = opacity, col = "lightgray")
planes3d(coefs["Food"], coefs["Service"], -1, coefs["(Intercept)"] + coefs["East"], alpha = opacity, col = "lightgray")
@

  \end{enumerate}

%\paragraph{ANOVA}

%\paragraph{Regression and Correlation}

% 
% \newpage
% 
% \section{Instructor's Notes}
% 
% 
% 	
% \begin{frame}
%   	\frametitle{Mathematical Treatment}
%   	\begin{align*}
%   		Y &= \beta_0 + \beta_1 \cdot X + \epsilon \\
%   		\begin{bmatrix} y_1 \\ \vdots \\ y_n \end{bmatrix} 
%   			&= \begin{bmatrix} 1 & x_1 \\ \vdots & \vdots \\ 1 & x_n \end{bmatrix}
%   				\begin{bmatrix} \beta_0 \\ \beta_1 \end{bmatrix}
%   				+ \begin{bmatrix} \epsilon_1 \\ \vdots \\ \epsilon_n \end{bmatrix} \\
%   		y &= \mathbf{X} \beta + \epsilon \\
%   		\Ex[y] &= \mathbf{X} \Ex[\beta] \\
%   		(\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \cdot \Ex[y] &= \Ex[\beta]
%   	\end{align*}
% 	\begin{itemize}
% 		\item Just a deterministic matrix computation -- not magic
% 		\item rather straightforward, fast on a computer
% 		\item Always contains the point $(\bar{x}, \bar{y})$
% 	\end{itemize}
% \end{frame}




\end{document}
