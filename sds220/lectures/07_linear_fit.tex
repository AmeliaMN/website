\documentclass[10pt]{article}\usepackage[]{graphicx}\usepackage[]{color}
%% maxwidth is the original width if it is less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\definecolor{fgcolor}{rgb}{0.345, 0.345, 0.345}
\newcommand{\hlnum}[1]{\textcolor[rgb]{0.686,0.059,0.569}{#1}}%
\newcommand{\hlstr}[1]{\textcolor[rgb]{0.192,0.494,0.8}{#1}}%
\newcommand{\hlcom}[1]{\textcolor[rgb]{0.678,0.584,0.686}{\textit{#1}}}%
\newcommand{\hlopt}[1]{\textcolor[rgb]{0,0,0}{#1}}%
\newcommand{\hlstd}[1]{\textcolor[rgb]{0.345,0.345,0.345}{#1}}%
\newcommand{\hlkwa}[1]{\textcolor[rgb]{0.161,0.373,0.58}{\textbf{#1}}}%
\newcommand{\hlkwb}[1]{\textcolor[rgb]{0.69,0.353,0.396}{#1}}%
\newcommand{\hlkwc}[1]{\textcolor[rgb]{0.333,0.667,0.333}{#1}}%
\newcommand{\hlkwd}[1]{\textcolor[rgb]{0.737,0.353,0.396}{\textbf{#1}}}%
\let\hlipl\hlkwb

\usepackage{framed}
\makeatletter
\newenvironment{kframe}{%
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\definecolor{shadecolor}{rgb}{.97, .97, .97}
\definecolor{messagecolor}{rgb}{0, 0, 0}
\definecolor{warningcolor}{rgb}{1, 0, 1}
\definecolor{errorcolor}{rgb}{1, 0, 0}
\newenvironment{knitrout}{}{} % an empty environment to be redefined in TeX

\usepackage{alltt}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{fancyhdr,url,hyperref}
\usepackage{graphicx,xspace}
\usepackage{subfigure}
\usepackage{tikz}
\usetikzlibrary{arrows,decorations.pathmorphing,backgrounds,positioning,fit,through}

\oddsidemargin 0in  %0.5in
\topmargin     0in
\leftmargin    0in
\rightmargin   0in
\textheight    9in
\textwidth     6in %6in
%\headheight    0in
%\headsep       0in
%\footskip      0.5in

\newtheorem{thm}{Theorem}
\newtheorem{cor}[thm]{Corollary}
\newtheorem{obs}{Observation}
\newtheorem{lemma}{Lemma}
\newtheorem{claim}{Claim}
\newtheorem{definition}{Definition}
\newtheorem{question}{Question}
\newtheorem{answer}{Answer}
\newtheorem{problem}{Problem}
\newtheorem{solution}{Solution}
\newtheorem{conjecture}{Conjecture}

\pagestyle{fancy}

\lhead{\textsc{Prof. McNamara}}
\chead{\textsc{SDS/MTH 220: Lecture notes}}
\lfoot{}
\cfoot{}
%\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.2pt}
\renewcommand{\footrulewidth}{0.0pt}

\newcommand{\ans}{\vspace{0.25in}}
\newcommand{\R}{{\sf R}\xspace}
\newcommand{\cmd}[1]{\texttt{#1}}
\newcommand{\Ex}{\mathbb{E}}

\rhead{\textsc{September 22, 2017}}
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\begin{document}

\paragraph{Agenda}
\begin{enumerate}
  \itemsep0em
  \item Mathematics behind linear regression
  \item Strength of Fit
\end{enumerate}

\paragraph{Mathematics behind linear regression}


Looking at the relationship between the $y_i$s, the $\hat{y}_i$s, and $\bar{y}$, we can see that
\begin{eqnarray*}
(y_i -\bar{y}) = (\hat{y_i}-\bar{y}) + (y_i -\hat{y_i})
\end{eqnarray*}
\vspace{1.5in}

We can use the relationship between those quantities to gain some intuition for this:
\begin{eqnarray*}
\sum_{i=1}^n (y_i -\bar{y})^2 &=& \sum_{i=1}^n (\hat{y_i}-\bar{y}) + \sum_{i=1}^n (y_i-\hat{y_i})^2 \\
SST &=& SSM + SSE
\end{eqnarray*}

$r$ is the correlation between two variables

\begin{eqnarray*}
r = \frac{1}{1-n}\sum_{i=1}^n \frac{x_i-\bar{x}}{s_x}\frac{y_i-\bar{y}}{s_y}
\end{eqnarray*}

and conveniently,

\begin{eqnarray*}
\hat{\beta}_1 = \frac{s_y}{s_x}\cdot r
\end{eqnarray*}

Once you know $\hat{\beta}_1$, you can find the intercept ($\hat{\beta}_0$) by plugging in $(\bar{x}, \bar{y})$-- a point that is always on the line. 

\begin{eqnarray*}
y-\bar{y}=\hat{\beta_1}(x -\bar{x})
\end{eqnarray*}

\paragraph{Example: Poverty and Education}

Is there an association between poverty and education among states? The following plot illustrates the relationship between the \emph{poverty rate} and the \emph{high school graduation rate} among all 50 states and the District of Columbia. 

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{require}\hlstd{(mosaic)}
\hlstd{poverty} \hlkwb{<-} \hlkwd{read.csv}\hlstd{(}\hlstr{"http://math.smith.edu/~bbaumer/mth241/poverty.txt"}\hlstd{,} \hlkwc{sep} \hlstd{=} \hlstr{"\textbackslash{}t"}\hlstd{)}
\hlkwd{qplot}\hlstd{(}\hlkwc{data} \hlstd{= poverty,} \hlkwc{x} \hlstd{= Graduates,} \hlkwc{y} \hlstd{= Poverty,} \hlkwc{xlab} \hlstd{=} \hlstr{"Graduation Rate"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"Poverty Rate"}\hlstd{)} \hlopt{+}
  \hlkwd{geom_smooth}\hlstd{(}\hlkwc{method} \hlstd{=} \hlstr{"lm"}\hlstd{,} \hlkwc{se} \hlstd{=} \hlnum{0}\hlstd{)}
\end{alltt}
\end{kframe}
\end{knitrout}

Use the following summary statistics to calculate the least squares regression line. 

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{favstats}\hlstd{(}\hlopt{~}\hlstd{Poverty,} \hlkwc{data} \hlstd{= poverty)}
\end{alltt}
\begin{verbatim}
##  min   Q1 median   Q3 max     mean       sd  n missing
##  5.6 9.25   10.6 13.4  18 11.34902 3.099185 51       0
\end{verbatim}
\begin{alltt}
\hlkwd{favstats}\hlstd{(}\hlopt{~}\hlstd{Graduates,} \hlkwc{data} \hlstd{= poverty)}
\end{alltt}
\begin{verbatim}
##   min   Q1 median   Q3  max     mean       sd  n missing
##  77.2 83.3   86.9 88.7 92.1 86.01176 3.725998 51       0
\end{verbatim}
\begin{alltt}
\hlkwd{cor}\hlstd{(Poverty} \hlopt{~} \hlstd{Graduates,} \hlkwc{data} \hlstd{= poverty)}
\end{alltt}
\begin{verbatim}
## [1] -0.7468583
\end{verbatim}
\end{kframe}
\end{knitrout}


\begin{itemize}
  \itemsep0.5in
  \item Slope:
  \item Intercept:
  \item Interpretation:
  \vspace{0.5in}
\end{itemize}


\paragraph{Measuring the Strength of Fit}

Just as we were able to quantify the strength of the linear relationship between two variables with the correlation coefficient, $r$, we can quantify the percentage of variation in the response variable ($y$) that is explained by the explanatory variables. This quantity is called the \emph{coefficient of determination} and is denoted $R^2$.

\begin{itemize}
  \itemsep0in
  \item Like any percentage, $R^2$ is always between 0 and 1
  \item For simple linear regression (one explanatory variable), $R^2 = r^2$
  \item $R^2 = 1 - SSE/SST = SSM/SST$
\end{itemize}

%\includegraphics[width=9cm]{poverty_scat}
\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{qplot}\hlstd{(}\hlkwc{data} \hlstd{= poverty,} \hlkwc{x} \hlstd{= Graduates,} \hlkwc{y} \hlstd{= Poverty,} \hlkwc{xlab} \hlstd{=} \hlstr{"Graduation Rate"}\hlstd{,} \hlkwc{ylab} \hlstd{=} \hlstr{"Poverty Rate"}\hlstd{)} \hlopt{+}
  \hlkwd{geom_smooth}\hlstd{(}\hlkwc{method} \hlstd{=} \hlstr{"lm"}\hlstd{,} \hlkwc{se} \hlstd{=} \hlnum{0}\hlstd{,} \hlkwc{size} \hlstd{=} \hlnum{3}\hlstd{)}
\hlstd{mod} \hlkwb{<-} \hlkwd{lm}\hlstd{(Poverty} \hlopt{~} \hlstd{Graduates,} \hlkwc{data} \hlstd{= poverty)}
\hlstd{n} \hlkwb{<-} \hlkwd{nrow}\hlstd{(poverty)}
\hlstd{SST} \hlkwb{<-} \hlkwd{var}\hlstd{(}\hlopt{~}\hlstd{Poverty,} \hlkwc{data} \hlstd{= poverty)} \hlopt{*} \hlstd{(n} \hlopt{-} \hlnum{1}\hlstd{)}
\hlstd{SSE} \hlkwb{<-} \hlkwd{var}\hlstd{(}\hlkwd{residuals}\hlstd{(mod))} \hlopt{*} \hlstd{(n} \hlopt{-} \hlnum{1}\hlstd{)}
\hlnum{1} \hlopt{-} \hlstd{SSE} \hlopt{/} \hlstd{SST}
\end{alltt}
\begin{verbatim}
## [1] 0.5577973
\end{verbatim}
\begin{alltt}
\hlkwd{rsquared}\hlstd{(mod)}
\end{alltt}
\begin{verbatim}
## [1] 0.5577973
\end{verbatim}
\end{kframe}
\end{knitrout}
\clearpage
\paragraph{RailTrail example}

Recall the RailTrail example from last time, in which we were trying to understand ridership ($volume$) in terms of temperature ($avgtemp$). We fit two models: a simple model in based strictly on the average volume, and a linear regression model for $volume$ as a function of $avgtemp$. The $R^2$ value for the second model was:

\begin{knitrout}\footnotesize
\definecolor{shadecolor}{rgb}{0.969, 0.969, 0.969}\color{fgcolor}\begin{kframe}
\begin{alltt}
\hlkwd{rsquared}\hlstd{(}\hlkwd{lm}\hlstd{(volume} \hlopt{~} \hlstd{avgtemp,} \hlkwc{data} \hlstd{= RailTrail))}
\end{alltt}
\begin{verbatim}
## [1] 0.1822039
\end{verbatim}
\begin{alltt}
\hlcom{# rsquared(lm(volume ~ 1, data=RailTrail))}
\end{alltt}
\end{kframe}
\end{knitrout}

\begin{enumerate}
  \itemsep0.5in
  \item What was the $R^2$ for the first model? Which one fit the data better? 
  \item Write a sentence interpretting the $R^2$ for the second model presented above.
  \vspace{0.5in}
\end{enumerate}


%' 
%' \newpage
%' 
%' 
% ' \newpage
% 
%  \paragraph{Solution to Fitting the Line}
% 
%  Do it by hand.
% 
%  <<fig.height=4, fig.width=10>>=
%  # summary stats to calculate slope and intercept
%  fv.p <- favstats(~Poverty, data = poverty)
%  fv.g <- favstats(~Graduates, data = poverty)
% fv.p
% fv.g
%  x.bar <- fv.g[1, "mean"]
% x.bar
%  s.x <- fv.g[1, "sd"]
% s.x
%  y.bar <- fv.p[1, "mean"]
% y.bar
%  s.y <- fv.p[1, "sd"]
% s.y
%  @
% 
%  <<fig.height=4, fig.width=10, fig.show='hold'>>=
%  xyplot(Poverty ~ Graduates, data = poverty, ylab = "% in poverty", xlab = "% HS grad", pch=19)
%  ladd(panel.abline(v = x.bar, lty=2))
%  ladd(panel.abline(h = y.bar, lty=2))
% 
%  R <- cor(Graduates ~ Poverty, data = poverty)
% R
%  b1 <- (s.y/s.x) * R
% b1
%  b0 <- y.bar + b1 * -x.bar
% b0
% 
%  mod <- lm(Poverty ~ Graduates, data = poverty)
%  coef(mod)
%  ladd(panel.abline(mod, lwd=2, col="goldenrod"))
%  @
% 
% 
%  <<>>=
%  binmod <- lm(volume ~ weekday, data = RailTrail)
%  rsquared(binmod)
%  plotModel(binmod)
%  @
% 
% End of notes

\end{document}
